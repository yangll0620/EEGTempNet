{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import import_nbmodule\n",
    "from EEGNet import EEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inter_pre_EEGNet(leaveonesubi):\n",
    "    \"\"\"\n",
    "    inter_pre_EEGNet return the inter-subject prediction accuracy for leaveonesubi base on EEGNet\n",
    "    \n",
    "    Input:\n",
    "        leaveonesubi: leave-one-subject validation in inter-subject case\n",
    "        \n",
    "    Output:\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    loadpath = os.path.join('..', '..', 'data')\n",
    "\n",
    "    ###########################\n",
    "    #\n",
    "    # load train and test data\n",
    "    #\n",
    "    ###########################\n",
    "    leaveonesubi = 1 \n",
    "    x_train = np.array([])\n",
    "    y_train = np.array([])\n",
    "    for subi in range(1,11):  \n",
    "        filename = 'alldata_sub' + str(subi) + '.mat'\n",
    "        matfile = os.path.join(loadpath, filename)\n",
    "        matdat = sio.loadmat(matfile, variable_names = ['eeg', 'labels_dummy', 'labels'])\n",
    "\n",
    "        if subi == leaveonesubi:\n",
    "            x_test = matdat['eeg'] # eeg: ntrials * nchns(31) * ntemporal\n",
    "            y_test = matdat['labels'] # labels: ntrials * 1\n",
    "        else:\n",
    "            if x_train.size == 0: # x_train = [] and y_train = []\n",
    "                x_train = matdat['eeg'] \n",
    "                y_train = matdat['labels']\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train,matdat['eeg']), axis = 0)\n",
    "                y_train = np.concatenate((y_train,matdat['labels']), axis = 0)\n",
    "    \n",
    "    \n",
    "    # expand the dim of x_train, x_test\n",
    "    x_train = np.expand_dims(x_train, axis = 3)  # expand x_train dim, xtrain: ntrials * nchns * ntemporal * 1\n",
    "    x_test = np.expand_dims(x_test, axis = 3) # expand x_test dim, xtest: ntrials * nchns * ntemporal * 1\n",
    "\n",
    "    # Converts a class vector (integers) to binary class matrix.\n",
    "    y_train_categorical = to_categorical(y_train)\n",
    "    y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "    ###########################################\n",
    "    #\n",
    "    # EEGNet config: F1, D, rate_dropbox, et.al\n",
    "    #\n",
    "    ###########################################\n",
    "    F1, D = 4, 2 # EEGNet-4,2\n",
    "    rate_dropout = 0.25 # paper used 0.5 for within-subject, and 0.25 for cross-subject\n",
    "    fs = 256 # figured out from previous code\n",
    "    input_shape = x_train[0].shape # input_shape = (nchns, ntemporal)\n",
    "    n_classes = len(np.unique(y_train))\n",
    "\n",
    "    model = EEGNet(F1 = F1, D = D, rate_dropout = rate_dropout, input_shape = input_shape, \n",
    "                   fs = fs, n_classes = n_classes)\n",
    "\n",
    "    # training\n",
    "    history = model.fit(x_train, y_train_categorical, batch_size=200, epochs=50, validation_split=0, verbose=1)\n",
    "    \n",
    "    # predict test\n",
    "    y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 1.1272 - acc: 0.3647\n",
      "Epoch 2/50\n",
      "15057/15057 [==============================] - 30s 2ms/step - loss: 1.0616 - acc: 0.4286\n",
      "Epoch 3/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 1.0151 - acc: 0.4737\n",
      "Epoch 4/50\n",
      "15057/15057 [==============================] - 40s 3ms/step - loss: 0.9826 - acc: 0.4954\n",
      "Epoch 5/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.9563 - acc: 0.5168\n",
      "Epoch 6/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.9357 - acc: 0.5369\n",
      "Epoch 7/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.9173 - acc: 0.5602\n",
      "Epoch 8/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.9047 - acc: 0.5687\n",
      "Epoch 9/50\n",
      "15057/15057 [==============================] - 34s 2ms/step - loss: 0.8895 - acc: 0.5773\n",
      "Epoch 10/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8766 - acc: 0.5868\n",
      "Epoch 11/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8690 - acc: 0.5975\n",
      "Epoch 12/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.8581 - acc: 0.5984\n",
      "Epoch 13/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8508 - acc: 0.6013\n",
      "Epoch 14/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.8493 - acc: 0.6066\n",
      "Epoch 15/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8445 - acc: 0.6066\n",
      "Epoch 16/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8373 - acc: 0.6122\n",
      "Epoch 17/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8346 - acc: 0.6139\n",
      "Epoch 18/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.8325 - acc: 0.6135\n",
      "Epoch 19/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.8254 - acc: 0.6192\n",
      "Epoch 20/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8319 - acc: 0.6143\n",
      "Epoch 21/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8252 - acc: 0.6180\n",
      "Epoch 22/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8184 - acc: 0.6219\n",
      "Epoch 23/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.8201 - acc: 0.6201\n",
      "Epoch 24/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.8147 - acc: 0.6217\n",
      "Epoch 25/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.8105 - acc: 0.6258\n",
      "Epoch 26/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8121 - acc: 0.6228\n",
      "Epoch 27/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.8149 - acc: 0.6250\n",
      "Epoch 28/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8103 - acc: 0.6287\n",
      "Epoch 29/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8074 - acc: 0.6333\n",
      "Epoch 30/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8104 - acc: 0.6273\n",
      "Epoch 31/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8030 - acc: 0.6309\n",
      "Epoch 32/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8047 - acc: 0.6291\n",
      "Epoch 33/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8082 - acc: 0.6327\n",
      "Epoch 34/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.8022 - acc: 0.6336\n",
      "Epoch 35/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.7989 - acc: 0.6316\n",
      "Epoch 36/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.8011 - acc: 0.6286\n",
      "Epoch 37/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.7949 - acc: 0.6337\n",
      "Epoch 38/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.7991 - acc: 0.6366\n",
      "Epoch 39/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.8004 - acc: 0.6331\n",
      "Epoch 40/50\n",
      "15057/15057 [==============================] - 31s 2ms/step - loss: 0.7966 - acc: 0.6375\n",
      "Epoch 41/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.7962 - acc: 0.6348\n",
      "Epoch 42/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.7929 - acc: 0.6352\n",
      "Epoch 43/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.7930 - acc: 0.6333\n",
      "Epoch 44/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.7918 - acc: 0.6410\n",
      "Epoch 45/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.7890 - acc: 0.6396\n",
      "Epoch 46/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.7955 - acc: 0.6355\n",
      "Epoch 47/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.7949 - acc: 0.6305\n",
      "Epoch 48/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.7966 - acc: 0.6329\n",
      "Epoch 49/50\n",
      "15057/15057 [==============================] - 32s 2ms/step - loss: 0.7934 - acc: 0.6378\n",
      "Epoch 50/50\n",
      "15057/15057 [==============================] - 33s 2ms/step - loss: 0.7901 - acc: 0.6442\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5c7f818a199f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mleaveonesubi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minter_pre_EEGNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaveonesubi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-56d2743ebc62>\u001b[0m in \u001b[0;36minter_pre_EEGNet\u001b[0;34m(leaveonesubi)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# predict test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "leaveonesubi = 1\n",
    "inter_pre_EEGNet(leaveonesubi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
